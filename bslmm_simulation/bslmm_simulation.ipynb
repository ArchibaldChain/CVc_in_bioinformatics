{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BSLMM Simulation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian method v.s. LMM\n",
    "\n",
    "##### Bayesian method\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\mathbf{y}=1_n \\mu+\\mathbf{X} \\boldsymbol{\\beta}+\\boldsymbol{\\varepsilon} \\\\\n",
    "\\beta_i \\sim \\mathrm{N}\\left(0, \\sigma_b^2 /(p \\tau)\\right)\\\\\n",
    "\\boldsymbol{\\varepsilon} \\sim \\mathrm{MVN}_n\\left(0, \\mathbf{I}_n \\tau^{-1}\\right)\\\\\n",
    "\\end{gathered} \\\\\n",
    "$$\n",
    "\n",
    "##### LMM\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\mathbf{y}=1_n \\mu+\\mathbf{X} \\boldsymbol{\\beta}+ \\boldsymbol{u} +\\boldsymbol{\\varepsilon} \\\\\n",
    "\\boldsymbol{u} \\sim \\mathrm{MVN}\\left(0, \\sigma_b ^2 \\tau^{-1} \\mathbf{K}\\right)\\\\\n",
    "\\boldsymbol{\\varepsilon} \\sim \\mathrm{MVN}_n\\left(0, \\mathbf{I}_n \\tau^{-1}\\right)\n",
    "\\end{gathered} \\\\\n",
    "$$\n",
    "where $\\mathbf{K} = 1/p W W ^{\\top}$\n",
    "\n",
    "The above LMM model is equivalent to the bayesian model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$K = 1/p X X^{\\top}$\n",
    "$K_{tr,te} = 1/p X_{tr} X_{te} ^{\\top}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSLMM v.s. LMM\n",
    "##### BSLMM\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\mathbf{y}=1_{n} \\mu+\\mathbf{X} \\tilde{\\beta}+\\mathbf{u}+\\boldsymbol{\\varepsilon} \\\\\n",
    "\\mathbf{u} \\sim \\mathbf{M V N}_{n}\\left(0, \\sigma_{b}^{2} \\tau^{-1} \\mathbf{K}\\right), \\\\\n",
    "\\boldsymbol{\\varepsilon} \\sim \\operatorname{MVN}_{n}\\left(0, \\tau^{-1} \\mathbf{I}_{n}\\right) \\\\\n",
    "\\tilde{\\beta}_{i} \\sim \\pi \\mathbf{N}\\left(0, \\sigma_{a}^{2} \\tau^{-1}\\right)+(1-\\pi) \\delta_{0},\n",
    "\\end{gathered}\n",
    "$$\n",
    "(hyper-)parameters, $\\mu, \\tau, \\pi, \\sigma_{a}$, and $\\sigma_{b}$.\n",
    "\n",
    "- $\\mu$ and $\\tau^{-1}$ control the phenotype mean and residual variance.\n",
    "- $\\pi$ controls the proportion of $\\tilde{\\boldsymbol{\\beta}}$ values in (6) that are non-zero.\n",
    "- $\\sigma_{a}$ controls the expected magnitude of the (non-zero) $\\tilde{\\boldsymbol{\\beta}}$.\n",
    "- $\\sigma_{b}$ controls the expected magnitude of the random effects $\\mathbf{u}$.\n",
    "\n",
    "##### Bayesian Linear Models\n",
    "\n",
    "$$\n",
    "\\mathbf{y}=1_n \\mu+ \\mathbf{X} \\tilde{\\tilde \\beta_i} +\\boldsymbol{\\varepsilon} \\\\\n",
    "\\tilde{\\tilde \\beta_i} \\sim \\pi \\mathrm{N}\\left(0,\\left(\\sigma_a^2+\\sigma_b^2\\right) /(p \\tau)\\right)+(1-\\pi) \\mathrm{N}\\left(0, \\sigma_b^2 /(p \\tau)\\right)\n",
    "$$\n",
    "\n",
    "##### LMM2\n",
    "$$\n",
    "\\mathbf{y}=1_{n} \\mu+\\mathbf{X} {\\beta} + \\mathbf{w} +\\mathbf{u}+\\boldsymbol{\\varepsilon} \\\\\n",
    "\\mathbf{w} \\sim \\mathbf{M V N}_{n}\\left(0, \\sigma_{b}^{2} \\tau^{-1} \\mathbf{W}\\right), \\\\\n",
    "\\mathbf{u} \\sim \\mathbf{M V N}_{n}\\left(0, \\sigma_{b}^{2} \\tau^{-1} \\mathbf{K}\\right), \\\\\n",
    "\\boldsymbol{\\varepsilon} \\sim \\operatorname{MVN}_{n}\\left(0, \\tau^{-1} \\mathbf{I}_{n}\\right) \\\\\n",
    "$$\n",
    "where $\\mathbf{W} = 1/p X X ^{\\top}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define $V = \\sigma_{a}^{2} \\tau^{-1} \\mathbf{W} + \\sigma_{b}^{2} \\tau^{-1} \\mathbf{K}$\n",
    "\n",
    "Using weighted least square, we get $\\hat \\beta = (X^{\\top} V^{-1}X)^{-1} X^{\\top} V^ {-1} y$\n",
    "\n",
    "Let $v = w + u$ we have $v \\sim \\mathbf{MVN}_{n}(0, \\tau^{-1} (\\sigma_a^2 W + \\sigma_b^2 K) )$.\n",
    "\n",
    "Using BLUP, we get \n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat v = & E(v|y)\\\\\n",
    "    = & \\tau^{-1} (\\hat \\sigma_a^2 W + \\hat \\sigma_b^2 K) V^{-1} (y - X \\hat \\beta) \\\\\n",
    "    = & \\tau^{-1} (\\hat \\sigma_a^2 W + \\hat \\sigma_b^2 K) V^{-1} (\\mathbf{I} - X \\hat (X^{\\top} V^{-1}X)^{-1} X^{\\top} V^ {-1}) y\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can use the linear mixed model correction to correct the BSLMM\n",
    "$$\n",
    "H_{cv} = X (X^{\\top} V^{-1}X)^{-1} X^{\\top} V^ {-1} + \\tau^{-1} (\\hat \\sigma_a^2 W + \\hat \\sigma_b^2 K) V^{-1} (\\mathbf{I} - X \\hat (X^{\\top} V^{-1}X)^{-1} X^{\\top} V^ {-1})\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "K = 1/p X_k X_{-k}^{\\top}\\\\\n",
    "\n",
    "H_{cv} = X_k (X^{\\top} V^{-1}X)^{-1} X^{\\top} V^ {-1} + \\tau^{-1} (\\hat \\sigma_a^2 W + \\hat \\sigma_b^2 K) V^{-1} (\\mathbf{I} - X \\hat (X^{\\top} V^{-1}X)^{-1} X^{\\top} V^ {-1})\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the corrected CV is\n",
    "$$\n",
    "\\text{CV}_c = CV + H_{cv} Cov(y_{tr}, y_{te})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gamma_output_reader import GammaOutputReader as GOR\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv, gamma, hyper, para = GOR.read_output('./gamma_output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./data/10000SNPs.bimbam.csv')\n",
    "X = data.iloc[:,3:].to_numpy()\n",
    "p = X.shape[1]\n",
    "W = 1/p * X @ X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './gamma_output/'\n",
    "gor = GOR(output_path ,X, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_a2, s_b2 = gor.get_var_component()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4242869745838029, 0.8665811573602619)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gor.get_var_component()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331.089676332306"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gor.bv.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K =  1/p * X @ X.T\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
