{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate the Pheno-type data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Choose $n = 20$ genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\OneDrive\\Programming\\Python\\CVc_in_bio_informatics\n",
      "['Chr1First2000.vcf', 'filtered_test.vcf', 'selected_genes.csv', 'Simulated_SNPs.csv', 'SNP_in_200GENE_chr1.csv', 'SNP_in_20GENE_chr1.csv', 'testData.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Archibald\\AppData\\Local\\Temp\\ipykernel_130464\\2278546344.py:4: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(file, error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "print(os.listdir('./data'))\n",
    "file = 'data/SNP_in_200GENE_chr1.csv'\n",
    "data = pd.read_csv(file, error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10297, 2550)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENE</th>\n",
       "      <th>POS</th>\n",
       "      <th>HG00096</th>\n",
       "      <th>HG00097</th>\n",
       "      <th>HG00099</th>\n",
       "      <th>HG00100</th>\n",
       "      <th>HG00101</th>\n",
       "      <th>HG00102</th>\n",
       "      <th>HG00103</th>\n",
       "      <th>HG00104</th>\n",
       "      <th>...</th>\n",
       "      <th>NA21128</th>\n",
       "      <th>NA21129</th>\n",
       "      <th>NA21130</th>\n",
       "      <th>NA21133</th>\n",
       "      <th>NA21135</th>\n",
       "      <th>NA21137</th>\n",
       "      <th>NA21141</th>\n",
       "      <th>NA21142</th>\n",
       "      <th>NA21143</th>\n",
       "      <th>NA21144</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269039</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269373</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269650</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2550 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              GENE      POS  HG00096  HG00097  HG00099  HG00100  HG00101  \\\n",
       "0  ENSG00000227634  8269039        2        2        1        2        2   \n",
       "1  ENSG00000227634  8269341        0        0        0        0        0   \n",
       "2  ENSG00000227634  8269373        2        2        1        2        2   \n",
       "3  ENSG00000227634  8269650        2        2        1        2        2   \n",
       "4  ENSG00000227634  8269712        0        0        0        0        0   \n",
       "\n",
       "   HG00102  HG00103  HG00104  ...  NA21128  NA21129  NA21130  NA21133  \\\n",
       "0        1        1        2  ...        1        2        1        2   \n",
       "1        0        0        0  ...        0        0        0        0   \n",
       "2        1        1        2  ...        1        2        1        2   \n",
       "3        1        1        2  ...        1        2        1        1   \n",
       "4        0        0        0  ...        0        0        0        0   \n",
       "\n",
       "   NA21135  NA21137  NA21141  NA21142  NA21143  NA21144  \n",
       "0        1        2        2        1        2        1  \n",
       "1        0        0        0        0        0        0  \n",
       "2        1        2        2        1        2        1  \n",
       "3        1        2        2        1        2        1  \n",
       "4        0        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 2550 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENE</th>\n",
       "      <th>POS</th>\n",
       "      <th>HG00096</th>\n",
       "      <th>HG00097</th>\n",
       "      <th>HG00099</th>\n",
       "      <th>HG00100</th>\n",
       "      <th>HG00101</th>\n",
       "      <th>HG00102</th>\n",
       "      <th>HG00103</th>\n",
       "      <th>HG00104</th>\n",
       "      <th>...</th>\n",
       "      <th>NA21129</th>\n",
       "      <th>NA21130</th>\n",
       "      <th>NA21133</th>\n",
       "      <th>NA21135</th>\n",
       "      <th>NA21137</th>\n",
       "      <th>NA21141</th>\n",
       "      <th>NA21142</th>\n",
       "      <th>NA21143</th>\n",
       "      <th>NA21144</th>\n",
       "      <th>gene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269039</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ENSG00000227634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000227634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269373</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ENSG00000227634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269650</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ENSG00000227634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000227634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2551 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              GENE      POS  HG00096  HG00097  HG00099  HG00100  HG00101  \\\n",
       "0  ENSG00000227634  8269039        2        2        1        2        2   \n",
       "1  ENSG00000227634  8269341        0        0        0        0        0   \n",
       "2  ENSG00000227634  8269373        2        2        1        2        2   \n",
       "3  ENSG00000227634  8269650        2        2        1        2        2   \n",
       "4  ENSG00000227634  8269712        0        0        0        0        0   \n",
       "\n",
       "   HG00102  HG00103  HG00104  ...  NA21129  NA21130  NA21133  NA21135  \\\n",
       "0        1        1        2  ...        2        1        2        1   \n",
       "1        0        0        0  ...        0        0        0        0   \n",
       "2        1        1        2  ...        2        1        2        1   \n",
       "3        1        1        2  ...        2        1        1        1   \n",
       "4        0        0        0  ...        0        0        0        0   \n",
       "\n",
       "   NA21137  NA21141  NA21142  NA21143  NA21144             gene  \n",
       "0        2        2        1        2        1  ENSG00000227634  \n",
       "1        0        0        0        0        0  ENSG00000227634  \n",
       "2        2        2        1        2        1  ENSG00000227634  \n",
       "3        2        2        1        2        1  ENSG00000227634  \n",
       "4        0        0        0        0        0  ENSG00000227634  \n",
       "\n",
       "[5 rows x 2551 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gene'] = data.GENE.astype('category')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gene\n",
       "ENSG00000001461    [ENSG00000001461]\n",
       "ENSG00000018625    [ENSG00000018625]\n",
       "ENSG00000084070    [ENSG00000084070]\n",
       "ENSG00000084072    [ENSG00000084072]\n",
       "ENSG00000116147    [ENSG00000116147]\n",
       "                         ...        \n",
       "ENSG00000268172    [ENSG00000268172]\n",
       "ENSG00000271647    [ENSG00000271647]\n",
       "ENSG00000271810    [ENSG00000271810]\n",
       "ENSG00000272084    [ENSG00000272084]\n",
       "ENSG00000273002    [ENSG00000273002]\n",
       "Name: GENE, Length: 136, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('gene').GENE.unique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalIndex(['ENSG00000116704', 'ENSG00000162378', 'ENSG00000162374',\n",
      "                  'ENSG00000168710', 'ENSG00000121644', 'ENSG00000116353',\n",
      "                  'ENSG00000237413', 'ENSG00000143190', 'ENSG00000203739',\n",
      "                  'ENSG00000134198', 'ENSG00000153207', 'ENSG00000229956',\n",
      "                  'ENSG00000198198', 'ENSG00000172380', 'ENSG00000143702',\n",
      "                  'ENSG00000225006', 'ENSG00000117461', 'ENSG00000117602',\n",
      "                  'ENSG00000143344', 'ENSG00000162688'],\n",
      "                 categories=['ENSG00000001461', 'ENSG00000018625', 'ENSG00000084070', 'ENSG00000084072', 'ENSG00000116147', 'ENSG00000116353', 'ENSG00000116497', 'ENSG00000116704', ...], ordered=False, dtype='category', name='gene')\n"
     ]
    }
   ],
   "source": [
    "# Selecting 20 Genes that have more than 100 SNPs\n",
    "n = 20\n",
    "counts = data.groupby('gene').size().sort_values(ascending=False) \n",
    "groups = counts[counts > 100].sample(n, replace = False, random_state = 1 ).index\n",
    "\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5443\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENE</th>\n",
       "      <th>POS</th>\n",
       "      <th>HG00096</th>\n",
       "      <th>HG00097</th>\n",
       "      <th>HG00099</th>\n",
       "      <th>HG00100</th>\n",
       "      <th>HG00101</th>\n",
       "      <th>HG00102</th>\n",
       "      <th>HG00103</th>\n",
       "      <th>HG00104</th>\n",
       "      <th>...</th>\n",
       "      <th>NA21129</th>\n",
       "      <th>NA21130</th>\n",
       "      <th>NA21133</th>\n",
       "      <th>NA21135</th>\n",
       "      <th>NA21137</th>\n",
       "      <th>NA21141</th>\n",
       "      <th>NA21142</th>\n",
       "      <th>NA21143</th>\n",
       "      <th>NA21144</th>\n",
       "      <th>gene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>ENSG00000117602</td>\n",
       "      <td>24830297</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENSG00000117602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>ENSG00000117602</td>\n",
       "      <td>24831517</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENSG00000117602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>ENSG00000117602</td>\n",
       "      <td>24832009</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000117602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>ENSG00000117602</td>\n",
       "      <td>24835018</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENSG00000117602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>ENSG00000117602</td>\n",
       "      <td>24835171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENSG00000117602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2551 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GENE       POS  HG00096  HG00097  HG00099  HG00100  HG00101  \\\n",
       "331  ENSG00000117602  24830297        2        2        2        2        2   \n",
       "332  ENSG00000117602  24831517        2        2        2        2        2   \n",
       "333  ENSG00000117602  24832009        2        2        1        0        1   \n",
       "334  ENSG00000117602  24835018        2        2        1        2        2   \n",
       "335  ENSG00000117602  24835171        0        0        1        2        1   \n",
       "\n",
       "     HG00102  HG00103  HG00104  ...  NA21129  NA21130  NA21133  NA21135  \\\n",
       "331        2        2        2  ...        2        2        2        2   \n",
       "332        2        2        2  ...        2        2        2        2   \n",
       "333        2        2        1  ...        1        2        2        0   \n",
       "334        1        1        1  ...        2        1        2        2   \n",
       "335        0        0        1  ...        1        0        0        2   \n",
       "\n",
       "     NA21137  NA21141  NA21142  NA21143  NA21144             gene  \n",
       "331        2        2        2        2        2  ENSG00000117602  \n",
       "332        2        2        2        2        2  ENSG00000117602  \n",
       "333        2        2        1        0        0  ENSG00000117602  \n",
       "334        2        2        2        2        2  ENSG00000117602  \n",
       "335        0        0        1        2        2  ENSG00000117602  \n",
       "\n",
       "[5 rows x 2551 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = [i for i,x in enumerate(data['gene']) if x in groups]\n",
    "data_selected = data.iloc[index, :]\n",
    "print(len(data_selected))\n",
    "data_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5443, 2551)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Archibald\\AppData\\Local\\Temp\\ipykernel_130464\\486112115.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected['sign'] = 0\n"
     ]
    }
   ],
   "source": [
    "# get the group names\n",
    "gene_names = list(data_selected.gene.unique())\n",
    "\n",
    "data_selected['sign'] = 0\n",
    "\n",
    "# Choose five SNPs as significant SNPs and 95 as small sigficance others are non-significant\n",
    "for gene in gene_names:\n",
    "    n = len(data_selected.loc[data_selected['gene'] == gene ,:])\n",
    "    sign =  [1] * 100  + [0] * (n - 100)\n",
    "    \n",
    "    data_selected.loc[data_selected['gene'] == gene ,'sign'] = sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Archibald\\AppData\\Local\\Temp\\ipykernel_130464\\1514404415.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected['sign'][:d] = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2000, 2552)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 5\n",
    "data_selected = data_selected.loc[data_selected['sign'] != 0,:]\n",
    "data_selected['sign'][:d] = 2\n",
    "data_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331    2\n",
       "332    2\n",
       "333    2\n",
       "334    2\n",
       "335    2\n",
       "Name: sign, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_selected['sign'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1995\n",
      "331    24.947468\n",
      "332     5.659078\n",
      "333    13.841445\n",
      "334    31.691016\n",
      "335    26.411258\n",
      "336    -1.692695\n",
      "337     1.645601\n",
      "338    -0.262158\n",
      "339    -0.178780\n",
      "340     0.711177\n",
      "Name: beta, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Beta\n",
    "np.random.seed(0)\n",
    "data_selected['beta'] = 0\n",
    "n = len(data_selected.loc[data_selected['sign'] == 2,'beta'])\n",
    "print(n)\n",
    "large_effect = 200\n",
    "data_selected.loc[data_selected['sign'] == 2,'beta'] = np.random.normal(0, np.sqrt(large_effect), n)\n",
    "\n",
    "n = len(data_selected.loc[data_selected['sign'] == 1,'beta'])\n",
    "print(n)\n",
    "small_effect = 3\n",
    "data_selected.loc[data_selected['sign'] == 1,'beta'] = np.random.normal(0, np.sqrt(small_effect), n)\n",
    "\n",
    "beta = data_selected.beta\n",
    "print(beta[:10])\n",
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>340</th>\n",
       "      <th>...</th>\n",
       "      <th>9963</th>\n",
       "      <th>9964</th>\n",
       "      <th>9965</th>\n",
       "      <th>9966</th>\n",
       "      <th>9967</th>\n",
       "      <th>9968</th>\n",
       "      <th>9969</th>\n",
       "      <th>9970</th>\n",
       "      <th>9971</th>\n",
       "      <th>9972</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HG00096</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00097</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00099</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00100</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00101</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         331   332   333   334   335   336   337   338   339   340   ...  \\\n",
       "HG00096     2     2     2     2     0     0     2     0     2     0  ...   \n",
       "HG00097     2     2     2     2     0     0     2     0     2     0  ...   \n",
       "HG00099     2     2     1     1     1     0     1     1     1     1  ...   \n",
       "HG00100     2     2     0     2     2     0     0     2     0     2  ...   \n",
       "HG00101     2     2     1     2     1     0     1     1     1     1  ...   \n",
       "\n",
       "         9963  9964  9965  9966  9967  9968  9969  9970  9971  9972  \n",
       "HG00096     1     1     1     0     1     0     1     0     0     0  \n",
       "HG00097     1     1     1     0     1     0     1     0     0     0  \n",
       "HG00099     0     0     1     0     0     0     0     0     0     0  \n",
       "HG00100     1     1     1     0     1     0     1     0     0     0  \n",
       "HG00101     1     1     1     0     1     0     1     0     0     0  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.preprocessing import StandardScaler \n",
    "SNP = data_selected.drop(['GENE', 'POS', 'gene', 'beta'], axis=1).T\n",
    "# ss = StandardScaler()\n",
    "# SNP.loc[:,:] = ss.fit_teansform(X = SNP.loc[:,:])\n",
    "\n",
    "SNP.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP1 = SNP.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2549,)\n",
      "The sigma_g^2 is 2609.2, and sigma_e^2 is 2609.2\n"
     ]
    }
   ],
   "source": [
    "temp = SNP1.values @ beta\n",
    "print(temp.shape)\n",
    "sigma_g2 = np.var(temp, ddof = 1) # get the overall variance\n",
    "h2 = 0.5 # heritability\n",
    "sigma_e2 = sigma_g2 * (1 - h2)/ h2\n",
    "print(\"The sigma_g^2 is {:.5}, and sigma_e^2 is {:.5}\".format(sigma_g2, sigma_e2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add bias term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.971712432704138\n",
      "(2000,)\n",
      "[22.97171243 24.94746752  5.65907751 13.84144531 31.69101554 26.41125838]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "beta0 = np.random.normal(0, np.sqrt(large_effect))\n",
    "print(beta0)\n",
    "print(beta.shape)\n",
    "# beta_ = np.append(beta, beta0)\n",
    "beta_ = np.insert(beta.values, 0, beta0)\n",
    "print(beta_[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP.insert(loc=0, column='bias', value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2549, 2001)\n",
      "(2001,)\n"
     ]
    }
   ],
   "source": [
    "residual = np.random.normal(0, np.sqrt(sigma_e2), len(SNP))\n",
    "print(SNP.values.shape)\n",
    "print(beta_.shape)\n",
    "SNP['Y'] = SNP1.values @ beta + residual + beta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2621.7283570707173 2608.213410736963 0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.var(residual), np.var(SNP1.values @ beta), np.var(beta0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5017.581743311149"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(SNP['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>...</th>\n",
       "      <th>9964</th>\n",
       "      <th>9965</th>\n",
       "      <th>9966</th>\n",
       "      <th>9967</th>\n",
       "      <th>9968</th>\n",
       "      <th>9969</th>\n",
       "      <th>9970</th>\n",
       "      <th>9971</th>\n",
       "      <th>9972</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HG00096</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.377100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00097</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97.792189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00099</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.652598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00100</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.151941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00101</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.198573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         bias  331  332  333  334  335  336  337  338  339  ...  9964  9965  \\\n",
       "HG00096     1    2    2    2    2    0    0    2    0    2  ...     1     1   \n",
       "HG00097     1    2    2    2    2    0    0    2    0    2  ...     1     1   \n",
       "HG00099     1    2    2    1    1    1    0    1    1    1  ...     0     1   \n",
       "HG00100     1    2    2    0    2    2    0    0    2    0  ...     1     1   \n",
       "HG00101     1    2    2    1    2    1    0    1    1    1  ...     1     1   \n",
       "\n",
       "         9966  9967  9968  9969  9970  9971  9972           Y  \n",
       "HG00096     0     1     0     1     0     0     0   89.377100  \n",
       "HG00097     0     1     0     1     0     0     0   97.792189  \n",
       "HG00099     0     0     0     0     0     0     0    7.652598  \n",
       "HG00100     0     1     0     1     0     0     0  121.151941  \n",
       "HG00101     0     1     0     1     0     0     0  -18.198573  \n",
       "\n",
       "[5 rows x 2002 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Simulated Parameters and data\n",
    "SNP.to_csv('data/Simulated_SNPs.csv')\n",
    "np.savez('Parameters/simulated_parameters.npz', sigma_e2 =sigma_e2,sigma_g2 =sigma_g2, h2 = h2, beta = beta_, large_effect_terms = d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folds_indices(nfolds, n_tr):\n",
    "    if nfolds <= n_tr:\n",
    "        fold_size = int(np.floor(n_tr/nfolds))\n",
    "        resi = n_tr % nfolds\n",
    "        fold_sizes = [0] + resi * [fold_size +1] + (nfolds - resi) * [fold_size]\n",
    "        indices = np.cumsum(fold_sizes)\n",
    "        folds_indices = [(indices[i], indices[i + 1])  for i in range(nfolds)]\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Number of folds is larger than numer of samples\")\n",
    "    print('First 5 fold indices : {}'.format(folds_indices[:5]))\n",
    "    return folds_indices\n",
    "    \n",
    "def getHcv_for_Kfolds(X_tr, y_tr,  H_function, V = None, nfolds = 10):\n",
    "    n_tr,p = X_tr.shape\n",
    "    Hcv_k = np.zeros([n_tr,n_tr])\n",
    "    \n",
    "    folds_indices = get_folds_indices(nfolds = nfolds, n_tr = n_tr)\n",
    "    for Kindices in folds_indices:\n",
    "        ia,ib = Kindices\n",
    "        indices_minus_K = list(range(0, ia)) + list(range(ib, n_tr))\n",
    "\n",
    "        X_minus_K = X_tr[indices_minus_K,:]\n",
    "        y_minus_K = y_tr[indices_minus_K]\n",
    "        X_k = X_tr[ia:ib,:]\n",
    "        y_K = y_tr[ia:ib]\n",
    "\n",
    "        if V is not None:\n",
    "            V_minus_k = V[indices_minus_K,:][:, indices_minus_K]\n",
    "            temp = H_function(X_minus_K, X_k , y_minus_K, y_K, V_minus_k)\n",
    "        else:\n",
    "            temp = H_function(X_minus_K, X_k , y_minus_K, y_K)\n",
    "\n",
    "        Hcv_k[ia:ib, indices_minus_K] = temp\n",
    "\n",
    "    return Hcv_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "\n",
    "def timing(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        print('--- start function ' + func.__name__, '---')\n",
    "        result = func(*args, **kwargs)\n",
    "        print('------ {:.4f} seconds -----'.format(time.time() - start_time))\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LMM (linear mixed model)\n",
    "Let the model be\n",
    "$$\n",
    "Y_i = \\sum_{j = 1}^{p} \\beta_j X_{i,j} + u_i +\\epsilon_i \\ \\text{where } i = 1, 2,3,\\dots,n\n",
    "$$\n",
    "where $(u_1, u_2, \\dots, u_n)^\\top \\sim MVN(0, \\sigma_g^2 K ) $ and $\\epsilon_i \\sim ^{i.i.d} N(0, \\sigma_e^2)$, and  $K = 1/p X X^\\top$, $\\sigma_e^2 = \\frac{1 - h^2}{h^2} \\sigma_g^2$ . \n",
    "\n",
    "> ? how to estimate $\\sigma_e \\text{ and } \\sigma_g$?  Maybe using REML? But it requires the indication of the clusters.\n",
    "\n",
    "We can write the model as \n",
    "$$\n",
    "Y_i = \\sum_{j = 1}^{p} \\beta_j X_{i,j} + \\epsilon_i^* \\ \\text{where } i = 1, 2,3,\\dots,n \\text{ and } \\boldsymbol{\\epsilon}^{*} = \\boldsymbol u + \\boldsymbol \\epsilon \\sim N_{n}(\\mathbf{0}, V)\n",
    "$$\n",
    "where $V = Var(Y|X\\beta) = \\sigma^2_g K + \\sigma^2_e I$\n",
    "\n",
    "So we need to estimate two of  $\\sigma_g, \\sigma_e \\text{or } h$\n",
    "\n",
    "so we can get estimate for $\\tilde{\\boldsymbol{\\beta}}:=\\left(X^{t} V^{-1} X\\right)^{-1} X^{t} V^{-1} \\boldsymbol{Y}$\n",
    "\n",
    "BLUP for $\\tilde u = E(u|Y) = \\sigma^2_g K V^{-1}(Y - X\\tilde \\beta)$\n",
    "\n",
    " And $\\hat Y = X \\tilde \\beta + \\tilde u$\n",
    "\n",
    "Now we can define $H$ by\n",
    "\n",
    "$H = X\\left(X^{t} V^{-1} X\\right)^{-1} X^{t} V^{-1} + \\sigma^2_g K V^{-1}(I - X\\left(X^{t} V^{-1} X\\right)^{-1} X^{t} V^{-1})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\widehat{C V}_{c}=\\frac{1}{n}\\left(\\boldsymbol{y}-H_{c v} \\boldsymbol{y}\\right)^{t}\\left(\\boldsymbol{y}-H_{c v} \\boldsymbol{y}\\right)+\\frac{2}{n}\\left[\\operatorname{tr}\\left(H_{c v} \\operatorname{Cov}(\\boldsymbol{y}, \\boldsymbol{y})\\right)-n \\boldsymbol{h}_{t e} \\operatorname{Cov}\\left(\\boldsymbol{y}_{t r}, y_{t e}\\right)\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get $V = Var(Y|X\\beta) = \\sigma^2_g K + \\sigma^2_e I$ where $K = 1/p X X^\\top$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\OneDrive\\Programming\\Python\\CVc_in_bio_informatics\\src\\frequentist_simulation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>...</th>\n",
       "      <th>9964</th>\n",
       "      <th>9965</th>\n",
       "      <th>9966</th>\n",
       "      <th>9967</th>\n",
       "      <th>9968</th>\n",
       "      <th>9969</th>\n",
       "      <th>9970</th>\n",
       "      <th>9971</th>\n",
       "      <th>9972</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HG00096</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.377100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00097</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97.792189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00099</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.652598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00100</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.151941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00101</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.198573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         bias  331  332  333  334  335  336  337  338  339  ...  9964  9965  \\\n",
       "HG00096     1    2    2    2    2    0    0    2    0    2  ...     1     1   \n",
       "HG00097     1    2    2    2    2    0    0    2    0    2  ...     1     1   \n",
       "HG00099     1    2    2    1    1    1    0    1    1    1  ...     0     1   \n",
       "HG00100     1    2    2    0    2    2    0    0    2    0  ...     1     1   \n",
       "HG00101     1    2    2    1    2    1    0    1    1    1  ...     1     1   \n",
       "\n",
       "         9966  9967  9968  9969  9970  9971  9972           Y  \n",
       "HG00096     0     1     0     1     0     0     0   89.377100  \n",
       "HG00097     0     1     0     1     0     0     0   97.792189  \n",
       "HG00099     0     0     0     0     0     0     0    7.652598  \n",
       "HG00100     0     1     0     1     0     0     0  121.151941  \n",
       "HG00101     0     1     0     1     0     0     0  -18.198573  \n",
       "\n",
       "[5 rows x 2002 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "print(os.getcwd())\n",
    "%matplotlib inline\n",
    "if not 'SNP' in locals():\n",
    "    SNP = pd.read_csv('../../data/Simulated_SNPs.csv', index_col=0)\n",
    "par = np.load('../../Parameters/simulated_parameters.npz')\n",
    "sigma_e2, sigma_g2, h2, beta, num_large_effet_terms = [par[params] for params in par.files]\n",
    "sigma_g2 = float(sigma_g2)\n",
    "sigma_e2 = float(sigma_e2)\n",
    "h2 = float(h2)\n",
    "SNP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.97171243, 24.94746752,  5.65907751, 13.84144531, 31.69101554,\n",
       "       26.41125838])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta[:num_large_effet_terms+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "scaler = SS()\n",
    "# y = scaler.fit_transform(SNP['Y'].to_numpy().reshape([-1,1]))\n",
    "y = SNP['Y'].to_numpy()\n",
    "y = y.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "SNP_ = SNP.copy()\n",
    "SNP_.drop('Y', inplace= True, axis = 1)\n",
    "data = SNP_.values\n",
    "G_tr, G_te, y_tr, y_te = train_test_split(data, y, test_size = 0.2, random_state = 123)\n",
    "\n",
    "# X_tr, X_te = G_tr[:, :num_large_effet_terms+1], G_te[:, :num_large_effet_terms+1]\n",
    "d = 100\n",
    "X_tr, X_te = G_tr[:, :d+1], G_te[:, :d +1]\n",
    "W_tr, W_te = G_tr[:, 1:], G_te[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2039, 1) (2039, 101) (2039, 2000) (510, 1) (510, 101) (510, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(y_tr.shape, X_tr.shape, W_tr.shape, y_te.shape, X_te.shape, W_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using FAST_LMM to estimate sigma_g2 and sigma_e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- FAST-LMM------------------\n",
      "LowRank is set as True, not using REML\n",
      "Rank of W is 1673, shape of W is (2039, 2000).\n",
      "--- 3.5709967613220215 seconds for SVD calculation ---\n",
      "Optimization Results:\n",
      "Delta is calculated as:  0.6387510565869324\n",
      "Maximum Likelihood is calculated as:  -11015.473992664456\n",
      "---------------Summary------------------\n",
      "LowRank is set as True, not using REML\n",
      "Heritability h2: 0.6102208117459431\n",
      "Sigma_g2: 3919.844336556006\n",
      "Sigma_e2: 2503.804711631452\n",
      "------ 58.35671782493591 seconds ------\n"
     ]
    }
   ],
   "source": [
    "# from FAST_LMM import utils as u\n",
    "sc = W_tr.shape[1]\n",
    "import sys\n",
    "sys.path.append('./../')\n",
    "from FAST_LMM import FASTLMM\n",
    "fast = FASTLMM(lowRank=True, REML = False)\n",
    "fast.fit(X_tr, y_tr, 1/np.sqrt(sc) * W_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6423.649048187458\n",
      "4916.9842717438105 5410.652842964886 5017.581743311135\n"
     ]
    }
   ],
   "source": [
    "print(fast.sigma_e2 + fast.sigma_g2)\n",
    "print(np.var(y_tr), np.var(y_te), np.var(np.concatenate([y_tr, y_te])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fast.plot_likelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2 =  0.6102208117459431\n",
      "6752.3536603108205 3876.4195753858376\n"
     ]
    }
   ],
   "source": [
    "#using theoreatical sigma\n",
    "# fast.sigma_e2 = sigma_e2\n",
    "# fast.sigma_g2 = sigma_g2\n",
    "\n",
    "print('h2 = ', 1/(1+fast.delta) )\n",
    "n, sc = W_tr.shape\n",
    "# varYhat = np.mean(np.diag(1/ sc * sigma_g2* W_tr @ W_tr.T + sigma_e2 * np.identity(n)))\n",
    "varYhat2 = np.mean(np.diag(1/ sc * fast.sigma_g2* W_tr @ W_tr.T + fast.sigma_e2 * np.identity(n)))\n",
    "# varY = np.var(y_tr - X_tr @ beta[ :num_large_effet_terms+1], ddof = 0)\n",
    "varY_minus_Xbeta = np.var(y_tr - X_tr @ fast.beta)\n",
    "print(varYhat2 , varY_minus_Xbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_te, sc_te = W_te.shape\n",
    "y_te_hat = fast.predict(X_te,  1/np.sqrt(sc_te)* W_te)\n",
    "y_tr_hat = fast.predict(X_tr, 1/np.sqrt(sc)* W_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_hat_wls = X_tr @ fast.beta\n",
    "y_te_hat_wls = X_te @ fast.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2039, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMM: training error is: 2305.494186011934  test error is: 3300.2165195903485\n",
      "WLS: training error is: 4847.516316957407  test error is: 5855.715343084603\n"
     ]
    }
   ],
   "source": [
    "tr_error = 1/n * (np.sum(np.square(y_tr_hat - y_tr)))\n",
    "te_error = 1/n_te * (np.sum(np.square(y_te_hat - y_te)))\n",
    "tr_error_wls = 1/n * (np.sum(np.square(y_tr_hat_wls - y_tr)))\n",
    "te_error_wls = 1/n_te * (np.sum(np.square(y_te_hat_wls - y_te)))\n",
    "print('LMM: training error is:', tr_error, ' test error is:', te_error)\n",
    "print('WLS: training error is:', tr_error_wls, ' test error is:', te_error_wls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of training and test error of using LMM, OLS, WLS\n",
    "First we calculate $H_{tr, LMM}$, which is $H = X\\left(X^{t} V^{-1} X\\right)^{-1} X^{t} V^{-1} + \\sigma^2_g K V^{-1}(I - X\\left(X^{t} V^{-1} X\\right)^{-1} X^{t} V^{-1})$\n",
    "\n",
    "Then we calculate $H_{tr, WLS}$, which is $H = X\\left(X^{t} V^{-1} X\\right)^{-1} X^{t} V^{-1}$.\n",
    "\n",
    "Finally we calculate $H_{tr, WLS}$, which is $H = X\\left(X^{t} X\\right)^{-1} X^{t}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FAST_LMM import utils as u\n",
    "n_tr,sc = W_tr.shape\n",
    "V_inv = fast.sigma_g2 / sc * W_tr @ W_tr.T + fast.sigma_e2 * np.identity(X_tr.shape[0])\n",
    "inverse_part = u.inv(X_tr.T @ fast.V_inv() @ X_tr)\n",
    "\n",
    "K = W_tr @ W_tr.T /sc\n",
    "H_wls = X_tr @ inverse_part @ X_tr.T @ fast.V_inv()\n",
    "add2 = sigma_g2 * K @ fast.V_inv() @ (np.identity(n_tr) - H_wls)\n",
    "H_lmm = H_wls + add2\n",
    "H_ols = X_tr @ u.inv(X_tr.T @ X_tr)@ X_tr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error of lmm is 2305.49, wls error is 4847.52, ols error is 3725.23, sigma_e2 is 2503.80\n",
      "The ratio is 1.00 : 2.54 : 1.62\n"
     ]
    }
   ],
   "source": [
    "y_tr_hat_lmm = H_lmm @ y_tr\n",
    "y_tr_hat_wls = H_wls @ y_tr\n",
    "y_tr_hat_ols = H_ols @ y_tr \n",
    "\n",
    "\n",
    "tr_error_lmm = 1/n_tr * (np.sum((y_tr - y_tr_hat)**2))\n",
    "tr_error_ols = 1/n_tr * (np.sum((y_tr - y_tr_hat_ols)**2))\n",
    "tr_error_wls = 1/n_tr * (np.sum((y_tr - y_tr_hat_wls)**2))\n",
    "\n",
    "print('Training error of lmm is {:.2f}, wls error is {:.2f}, ols error is {:.2f}, sigma_e2 is {:.2f}'.format(\n",
    "    tr_error_lmm, tr_error_wls, tr_error_ols, fast.sigma_e2))\n",
    "print('The ratio is {:.2f} : {:.2f} : {:.2f}'.format(1, te_error_wls/tr_error_lmm, tr_error_ols/tr_error_lmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tr,sc = W_tr.shape\n",
    "# V = fast.sigma_g2 / sc * W_tr @ W_tr.T + fast.sigma_e2 * np.identity(X_tr.shape[0])\n",
    "inverse_part = u.inv(X_tr.T @ fast.V_inv() @ X_tr)\n",
    "\n",
    "H_wls_te = X_te @ inverse_part @ X_tr.T @ fast.V_inv()\n",
    "K_te_tr = W_te @ W_tr.T /sc\n",
    "add2 = sigma_g2 * K_te_tr @ fast.V_inv() @ (np.identity(n_tr) - H_wls)\n",
    "H_lmm_te = H_wls_te + add2\n",
    "H_ols_te = X_te @ u.inv(X_tr.T @ X_tr)@ X_tr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error of lmm is 3674.59, wls error is 5855.72, ols error is 4635.66, sigma_e2 is 2503.80\n",
      "The ratio is 1.00 : 1.59 : 1.26\n"
     ]
    }
   ],
   "source": [
    "y_te_hat_lmm = H_lmm_te @ y_tr\n",
    "y_te_hat_wls = H_wls_te @ y_tr\n",
    "y_te_hat_ols = H_ols_te @ y_tr\n",
    "\n",
    "te_error_lmm = 1/n_te * (np.sum((y_te - y_te_hat_lmm)**2))\n",
    "te_error_ols = 1/n_te * (np.sum((y_te - y_te_hat_ols)**2))\n",
    "te_error_wls = 1/n_te * (np.sum((y_te - y_te_hat_wls)**2))\n",
    "\n",
    "print('test error of lmm is {:.2f}, wls error is {:.2f}, ols error is {:.2f}, sigma_e2 is {:.2f}'.format(\n",
    "    te_error_lmm, te_error_wls, te_error_ols, fast.sigma_e2))\n",
    "print('The ratio is {:.2f} : {:.2f} : {:.2f}'.format(1, te_error_wls/te_error_lmm, te_error_ols/te_error_lmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of     lmm is 2305.494186011934, wls is 4847.516316957868, and ols is 3725.22532711786\n",
      "The corrected tr error of lmm is 4947.133536800278, wls is 5968.10252121317, and ols is 6198.813929534688\n",
      "The test error of         lmm is 3674.58558200125, wls is 5855.715343084947, and ols is 4635.659955401074\n"
     ]
    }
   ],
   "source": [
    "V_tr_te = 1/sc * W_tr @ W_te.T * sigma_g2\n",
    "w_lmm = 2 *( 1/n_tr * np.trace(H_lmm @ fast.V()) - 1/ n_te * np.trace(H_lmm_te @ V_tr_te))\n",
    "w_wls = 2 *( 1/n_tr * np.trace(H_wls @ fast.V()) - 1/ n_te * np.trace(H_wls_te @ V_tr_te))\n",
    "w_ols = 2 *( 1/n_tr * np.trace(H_ols @ fast.V()) - 1/ n_te * np.trace(H_ols_te @ V_tr_te))\n",
    "\n",
    "\n",
    "tr_error_lmm_c = tr_error_lmm + w_lmm\n",
    "tr_error_wls_c = tr_error_wls + w_wls\n",
    "tr_error_ols_c = tr_error_ols + w_ols\n",
    "\n",
    "print('The training error of     lmm is {}, wls is {}, and ols is {}'.format(tr_error_lmm, tr_error_wls, tr_error_ols))\n",
    "print('The corrected tr error of lmm is {}, wls is {}, and ols is {}'.format(tr_error_lmm_c, tr_error_wls_c, tr_error_ols_c))\n",
    "print('The test error of         lmm is {}, wls is {}, and ols is {}'.format(te_error_lmm, te_error_wls, te_error_ols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave One out Cross-validation error of LMM WLS and OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using theoretical sigma values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_e2:  2609.2370423738284  sigma_g2:  2609.2370423738284\n"
     ]
    }
   ],
   "source": [
    "# summ = sigma_e2 + sigma_g2\n",
    "# sigma_e2 = sigma_e2/summ\n",
    "# sigma_g2 = sigma_g2/summ\n",
    "print('sigma_e2: ', sigma_e2, ' sigma_g2: ', sigma_g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Parameteres/H_cv LMM.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\OneDrive\\Programming\\Python\\CVc_in_bio_informatics\\simulation.ipynb Cell 56\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y105sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     H_cv_ols[i, indices_mi] \u001b[39m=\u001b[39m X_tr[i,:] \u001b[39m@\u001b[39m inverse2 \u001b[39m@\u001b[39m X_minusi\u001b[39m.\u001b[39mT \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y105sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# for i in range(n_tr):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y105sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#     indices_mi= list(range(n_tr))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y105sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m#     indices_mi.remove(i)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y105sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m#     H_cv_lmm[i, indices_mi] = H_cv_wls[i, indices_mi] + \\\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y105sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m#         V[i, indices_mi] @ u.inv(V[indices_mi,:][:,indices_mi])  @ (np.identity(n_tr - 1) - H_cv_temp[indices_mi,: ])\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y105sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m np\u001b[39m.\u001b[39;49msavez(\u001b[39m'\u001b[39;49m\u001b[39mParameteres/H_cv LMM.npz\u001b[39;49m\u001b[39m'\u001b[39;49m, H_cv_ols \u001b[39m=\u001b[39;49m H_cv_ols,H_cv_wls \u001b[39m=\u001b[39;49m H_cv_wls, H_cv_lmm\u001b[39m=\u001b[39;49m H_cv_lmm)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msavez\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:612\u001b[0m, in \u001b[0;36msavez\u001b[1;34m(file, *args, **kwds)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_savez_dispatcher)\n\u001b[0;32m    529\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msavez\u001b[39m(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m    530\u001b[0m     \u001b[39m\"\"\"Save several arrays into a single file in uncompressed ``.npz`` format.\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \n\u001b[0;32m    532\u001b[0m \u001b[39m    Provide arrays as keyword arguments to store them under the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    610\u001b[0m \n\u001b[0;32m    611\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 612\u001b[0m     _savez(file, args, kwds, \u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:709\u001b[0m, in \u001b[0;36m_savez\u001b[1;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    707\u001b[0m     compression \u001b[39m=\u001b[39m zipfile\u001b[39m.\u001b[39mZIP_STORED\n\u001b[1;32m--> 709\u001b[0m zipf \u001b[39m=\u001b[39m zipfile_factory(file, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m\"\u001b[39;49m, compression\u001b[39m=\u001b[39;49mcompression)\n\u001b[0;32m    711\u001b[0m \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m namedict\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    712\u001b[0m     fname \u001b[39m=\u001b[39m key \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.npy\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:101\u001b[0m, in \u001b[0;36mzipfile_factory\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mzipfile\u001b[39;00m\n\u001b[0;32m    100\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mallowZip64\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m \u001b[39mreturn\u001b[39;00m zipfile\u001b[39m.\u001b[39mZipFile(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\zipfile.py:1248\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1247\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1248\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mopen(file, filemode)\n\u001b[0;32m   1249\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m   1250\u001b[0m         \u001b[39mif\u001b[39;00m filemode \u001b[39min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Parameteres/H_cv LMM.npz'"
     ]
    }
   ],
   "source": [
    "n_tr,sc = W_tr.shape\n",
    "V = sigma_g2 / sc * W_tr @ W_tr.T + sigma_e2 * np.identity(n_tr)\n",
    "\n",
    "H_cv_lmm = np.zeros([n_tr,n_tr])\n",
    "H_cv_wls = np.zeros([n_tr,n_tr])\n",
    "H_cv_ols = np.zeros([n_tr,n_tr])\n",
    "\n",
    "H_cv_temp = np.zeros([n_tr,n_tr-1])\n",
    "# V_minusi_inv_storage = np.zeros([n_tr,n_tr-1,n_tr-1]) \n",
    "# Store the inverse of Variance to reduce time consumpution \n",
    "# Storge comsumption will be too large\n",
    "\n",
    "for i in range(n_tr):\n",
    "    indices_mi= list(range(n_tr))\n",
    "    indices_mi.remove(i)\n",
    "    V_minusi_inv = u.inv(V[indices_mi,:][:,indices_mi]) \n",
    "    X_minusi = X_tr[indices_mi, :]\n",
    "\n",
    "    inverse1 = u.inv(X_minusi.T @ V_minusi_inv @ X_minusi)\n",
    "    inverse2 = u.inv(X_minusi.T @  X_minusi)\n",
    "\n",
    "    beta_temp = inverse1 @ X_minusi.T @ V_minusi_inv\n",
    "    temp = X_tr[i,:] @ beta_temp\n",
    "    # H_cv_temp[i, ] = temp\n",
    "    H_cv_temp = X_minusi @ beta_temp\n",
    "\n",
    "    H_cv_wls[i, indices_mi] = temp\n",
    "    H_cv_lmm[i, indices_mi] = temp + \\\n",
    "        V[i, indices_mi] @ u.inv(V[indices_mi,:][:,indices_mi])  @\\\n",
    "             (np.identity(n_tr - 1) - H_cv_temp)\n",
    "\n",
    "    H_cv_ols[i, indices_mi] = X_tr[i,:] @ inverse2 @ X_minusi.T \n",
    "\n",
    "# for i in range(n_tr):\n",
    "#     indices_mi= list(range(n_tr))\n",
    "#     indices_mi.remove(i)\n",
    "#     H_cv_lmm[i, indices_mi] = H_cv_wls[i, indices_mi] + \\\n",
    "#         V[i, indices_mi] @ u.inv(V[indices_mi,:][:,indices_mi])  @ (np.identity(n_tr - 1) - H_cv_temp[indices_mi,: ])\n",
    "\n",
    "np.savez('Parameters/H_cv LMM.npz', H_cv_ols = H_cv_ols,H_cv_wls = H_cv_wls, H_cv_lmm= H_cv_lmm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Parameters/H_cv LMM2.npz', H_cv_ols = H_cv_ols,H_cv_wls = H_cv_wls, H_cv_lmm= H_cv_lmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Summary------------------\n",
      "LowRank is set as True, not using REML\n",
      "Heritability h2: 0.6191573585757943\n",
      "Sigma_g2: 0.8501751476287691\n",
      "Sigma_e2: 0.5229412917597077\n"
     ]
    }
   ],
   "source": [
    "fast.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV error of   lmm is 0.5724998389488071, wls is 0.801534662456013, and ols is 0.7889778369665089\n",
      "The CVc error of  lmm is 0.868915702942935, wls is 0.8481441721079157, and ols is 0.7940647601034707\n",
      "The test error of lmm is 0.6764402864058059, wls is 0.8932609152562827, and ols is 0.8572306437026114\n"
     ]
    }
   ],
   "source": [
    "# Using Test Error to estimate the Generalization error\n",
    "Error_cv_lmm = 1/n_tr * (np.sum(np.square(y_tr - H_cv_lmm @ y_tr)))\n",
    "Error_cv_wls = 1/n_tr * (np.sum(np.square(y_tr - H_cv_wls @ y_tr)))\n",
    "Error_cv_ols = 1/n_tr * (np.sum(np.square(y_tr - H_cv_ols @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "V_inv = fast.V_inv()\n",
    "# using theoretical sigma_g2 to get the Covariance(y_tr, y_te)\n",
    "V_tr_te = 1/sc * sigma_g2 * W_tr @ W_te.T\n",
    "\n",
    "H_te_wls = X_te @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv\n",
    "H_te_lmm = H_te_wls + V_tr_te.T @ V_inv @ (np.identity(n_tr) - X_tr @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv) \n",
    "H_te_ols = X_te @ u.inv(X_tr.T @ X_tr) @ X_tr.T\n",
    "\n",
    "V = fast.V(sigma_g2 = sigma_g2, sigma_e2 = sigma_e2)\n",
    "Correction_lmm = 2 * (1/n_tr * np.trace(H_cv_lmm @ V) - 1/n_te * np.trace(H_te_lmm @ V_tr_te))\n",
    "Correction_wls = 2 * (1/n_tr * np.trace(H_cv_wls @ V) - 1/n_te * np.trace(H_te_wls @ V_tr_te))\n",
    "Correction_ols = 2 * (1/n_tr * np.trace(H_cv_ols @ V) - 1/n_te * np.trace(H_te_ols @ V_tr_te))\n",
    "\n",
    "Error_cv_lmm_c = Error_cv_lmm + Correction_lmm\n",
    "Error_cv_wls_c = Error_cv_wls + Correction_wls\n",
    "Error_cv_ols_c = Error_cv_ols + Correction_ols\n",
    "\n",
    "Error_te_lmm = 1/n_te *(np.sum(np.square(y_te - H_te_lmm @ y_tr)))\n",
    "Error_te_wls = 1/n_te *(np.sum(np.square(y_te - H_te_wls @ y_tr)))\n",
    "Error_te_ols = 1/n_te *(np.sum(np.square(y_te - H_te_ols @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "print('The CV error of   lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm, Error_cv_wls, Error_cv_ols))\n",
    "print('The CVc error of  lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm_c, Error_cv_wls_c, Error_cv_ols_c))\n",
    "print('The test error of lmm is {}, wls is {}, and ols is {}'.format(Error_te_lmm, Error_te_wls, Error_te_ols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using estimated sigma value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Summary------------------\n",
      "LowRank is set as True, not using REML\n",
      "Heritability h2: 0.6102208117459431\n",
      "Sigma_g2: 3919.844336556006\n",
      "Sigma_e2: 2503.804711631452\n"
     ]
    }
   ],
   "source": [
    "fast.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\OneDrive\\Programming\\Python\\CVc_in_bio_informatics\\simulation.ipynb Cell 65\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y120sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     H_cv_temp \u001b[39m=\u001b[39m X_minusi \u001b[39m@\u001b[39m beta_temp\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y120sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     H_cv_wls2[i, indices_mi] \u001b[39m=\u001b[39m temp\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y120sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     H_cv_lmm2[i, indices_mi] \u001b[39m=\u001b[39m temp \u001b[39m+\u001b[39m \\\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y120sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         V[i, indices_mi] \u001b[39m@\u001b[39m u\u001b[39m.\u001b[39minv(V[indices_mi,:][:,indices_mi])  \u001b[39m@\u001b[39m\\\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y120sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m              (np\u001b[39m.\u001b[39;49midentity(n_tr \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m) \u001b[39m-\u001b[39;49m H_cv_temp)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y120sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     H_cv_ols2[i, indices_mi] \u001b[39m=\u001b[39m X_tr[i,:] \u001b[39m@\u001b[39m inverse2 \u001b[39m@\u001b[39m X_minusi\u001b[39m.\u001b[39mT \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y120sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m#   H_cv_temp[i, ] = temp\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y120sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y120sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# for i in range(n_tr):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y120sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m#     H_cv_lmm[i, indices_mi] = H_cv_wls[i, indices_mi] + \\\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y120sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m#         V[i, indices_mi] @ u.inv(V[indices_mi,:][:,indices_mi])  @ (np.identity(n_tr - 1) - H_cv_temp[indices_mi,: ])\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_tr,sc = W_tr.shape\n",
    "V = fast.sigma_g2 / sc * W_tr @ W_tr.T + fast.sigma_e2 * np.identity(n_tr)\n",
    "\n",
    "H_cv_lmm2 = np.zeros([n_tr,n_tr])\n",
    "H_cv_wls2 = np.zeros([n_tr,n_tr])\n",
    "H_cv_ols2 = np.zeros([n_tr,n_tr])\n",
    "\n",
    "H_cv_temp = np.zeros([n_tr,n_tr-1])\n",
    "# V_minusi_inv_storage = np.zeros([n_tr,n_tr-1,n_tr-1]) \n",
    "# Store the inverse of Variance to reduce time consumpution \n",
    "# Storge comsumption will be too large\n",
    "\n",
    "for i in range(n_tr):\n",
    "    indices_mi= list(range(n_tr))\n",
    "    indices_mi.remove(i)\n",
    "    V_minusi_inv = u.inv(V[indices_mi,:][:,indices_mi]) \n",
    "    X_minusi = X_tr[indices_mi, :]\n",
    "\n",
    "    inverse1 = u.inv(X_minusi.T @ V_minusi_inv @ X_minusi)\n",
    "    inverse2 = u.inv(X_minusi.T @  X_minusi)\n",
    "\n",
    "    beta_temp = inverse1 @ X_minusi.T @ V_minusi_inv\n",
    "    temp = X_tr[i,:] @ beta_temp\n",
    "    H_cv_temp = X_minusi @ beta_temp\n",
    "\n",
    "    H_cv_wls2[i, indices_mi] = temp\n",
    "    H_cv_lmm2[i, indices_mi] = temp + \\\n",
    "        V[i, indices_mi] @ u.inv(V[indices_mi,:][:,indices_mi])  @\\\n",
    "             (np.identity(n_tr - 1) - H_cv_temp)\n",
    "\n",
    "    H_cv_ols2[i, indices_mi] = X_tr[i,:] @ inverse2 @ X_minusi.T \n",
    "#   H_cv_temp[i, ] = temp\n",
    "\n",
    "# for i in range(n_tr):\n",
    "#     indices_mi= list(range(n_tr))\n",
    "#     indices_mi.remove(i)\n",
    "#     H_cv_lmm[i, indices_mi] = H_cv_wls[i, indices_mi] + \\\n",
    "#         V[i, indices_mi] @ u.inv(V[indices_mi,:][:,indices_mi])  @ (np.identity(n_tr - 1) - H_cv_temp[indices_mi,: ])\n",
    "\n",
    "np.savez('Parameters/H_cv LMM2.npz', H_cv_ols = H_cv_ols2,H_cv_wls = H_cv_wls2, H_cv_lmm= H_cv_lmm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hcvs = np.load('Parameters/H_cv LMM2.npz')\n",
    "H_cv_ols2, H_cv_wls2, H_cv_lmm2 = [Hcvs[params] for params in Hcvs.files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV error of   lmm is 0.5707, wls is 0.8152, and ols is 0.7890\n",
      "The CVc error of  lmm is 0.5905, wls is 0.8108, and ols is 0.7976\n",
      "The test error of lmm is 0.6228, wls is 0.8933, and ols is 0.8572\n"
     ]
    }
   ],
   "source": [
    "# Using Test Error to estimate the Generalization error\n",
    "Error_cv_lmm = 1/n_tr * (np.sum(np.square(y_tr - H_cv_lmm2 @ y_tr)))\n",
    "Error_cv_wls = 1/n_tr * (np.sum(np.square(y_tr - H_cv_wls2 @ y_tr)))\n",
    "Error_cv_ols = 1/n_tr * (np.sum(np.square(y_tr - H_cv_ols2 @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "V_inv = fast.V_inv()\n",
    "# using estimated sigma_g2 to get the Covariance(y_tr, y_te)\n",
    "V_tr_te = 1/sc * fast.sigma_g2 * W_tr @ W_te.T\n",
    "\n",
    "H_te_wls = X_te @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv\n",
    "H_te_lmm = H_te_wls + V_tr_te.T @ V_inv @ (np.identity(n_tr) - X_tr @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv) \n",
    "H_te_ols = X_te @ u.inv(X_tr.T @ X_tr) @ X_tr.T\n",
    "\n",
    "V = fast.V()\n",
    "Correction_lmm = 2 * (1/n_tr * np.trace(H_cv_lmm2 @ V) - 1/n_te * np.trace(H_te_lmm @ V_tr_te))\n",
    "Correction_wls = 2 * (1/n_tr * np.trace(H_cv_wls2 @ V) - 1/n_te * np.trace(H_te_wls @ V_tr_te))\n",
    "Correction_ols = 2 * (1/n_tr * np.trace(H_cv_ols2 @ V) - 1/n_te * np.trace(H_te_ols @ V_tr_te))\n",
    "\n",
    "Error_cv_lmm_c = Error_cv_lmm + Correction_lmm\n",
    "Error_cv_wls_c = Error_cv_wls + Correction_wls\n",
    "Error_cv_ols_c = Error_cv_ols + Correction_ols\n",
    "\n",
    "Error_te_lmm = 1/n_te *(np.sum(np.square(y_te - H_te_lmm @ y_tr)))\n",
    "Error_te_wls = 1/n_te *(np.sum(np.square(y_te - H_te_wls @ y_tr)))\n",
    "Error_te_ols = 1/n_te *(np.sum(np.square(y_te - H_te_ols @ y_tr)))\n",
    "\n",
    "print('The CV error of   lmm is {:.4f}, wls is {:.4f}, and ols is {:.4f}'.format(Error_cv_lmm, Error_cv_wls, Error_cv_ols))\n",
    "print('The CVc error of  lmm is {:.4f}, wls is {:.4f}, and ols is {:.4f}'.format(Error_cv_lmm_c, Error_cv_wls_c, Error_cv_ols_c))\n",
    "print('The test error of lmm is {:.4f}, wls is {:.4f}, and ols is {:.4f}'.format(Error_te_lmm, Error_te_wls, Error_te_ols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with null space of w_tr testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import null_space\n",
    "null_V = null_space(W_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_te_in_null_V = null_V.T\n",
    "n_te_in_null_V = W_te_in_null_V.shape[0]\n",
    "X_te_in_null_V = np.concatenate([np.ones([n_te_in_null_V,1]), W_te_in_null_V[:, :num_large_effet_terms]], axis = 1)\n",
    "np.random.seed(0)\n",
    "epsilon = np.random.normal(0, np.sqrt(sigma_e2), n_te_in_null_V)\n",
    "y_te_in_null_V = W_te_in_null_V @ beta[1:]  + beta[0] + epsilon\n",
    "y_te_in_null_V = scaler.transform(y_te_in_null_V.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV error of   lmm is 0.570717391987545, wls is 0.815208575193165, and ols is 0.7889778369665089\n",
      "The CVc error of  lmm is 2.3238096042522445, wls is 1.3077927355941676, and ols is 2.121293995129623\n",
      "The test error of lmm is 0.148646106478417, wls is 0.14864610647841697, and ols is 0.11105748282530126\n"
     ]
    }
   ],
   "source": [
    "# Using Test Error to estimate the Generalization error\n",
    "Error_cv_lmm = 1/n_tr * (np.sum(np.square(y_tr - H_cv_lmm2 @ y_tr)))\n",
    "Error_cv_wls = 1/n_tr * (np.sum(np.square(y_tr - H_cv_wls2 @ y_tr)))\n",
    "Error_cv_ols = 1/n_tr * (np.sum(np.square(y_tr - H_cv_ols2 @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "V_inv = fast.V_inv()\n",
    "# using estimated sigma_g2 to get the Covariance(y_tr, y_te)\n",
    "V_tr_te = 1/sc * fast.sigma_g2 * W_tr @ W_te_in_null_V.T\n",
    "\n",
    "H_te_wls = X_te_in_null_V @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv\n",
    "H_te_lmm = H_te_wls + V_tr_te.T @ V_inv @ (np.identity(n_tr) - X_tr @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv) \n",
    "H_te_ols = X_te_in_null_V @ u.inv(X_tr.T @ X_tr) @ X_tr.T\n",
    "\n",
    "V = fast.V()\n",
    "Correction_lmm = 2 * (1/n_tr * np.trace(H_cv_lmm2 @ V) - 1/n_te * np.trace(H_te_lmm @ V_tr_te))\n",
    "Correction_wls = 2 * (1/n_tr * np.trace(H_cv_wls2 @ V) - 1/n_te * np.trace(H_te_wls @ V_tr_te))\n",
    "Correction_ols = 2 * (1/n_tr * np.trace(H_cv_ols2 @ V) - 1/n_te * np.trace(H_te_ols @ V_tr_te))\n",
    "\n",
    "Error_cv_lmm_c = Error_cv_lmm + Correction_lmm\n",
    "Error_cv_wls_c = Error_cv_wls + Correction_wls\n",
    "Error_cv_ols_c = Error_cv_ols + Correction_ols\n",
    "\n",
    "Error_te_lmm = 1/n_te *(np.sum(np.square(y_te_in_null_V - H_te_lmm @ y_tr)))\n",
    "Error_te_wls = 1/n_te *(np.sum(np.square(y_te_in_null_V - H_te_wls @ y_tr)))\n",
    "Error_te_ols = 1/n_te *(np.sum(np.square(y_te_in_null_V - H_te_ols @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "print('The CV error of   lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm, Error_cv_wls, Error_cv_ols))\n",
    "print('The CVc error of  lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm_c, Error_cv_wls_c, Error_cv_ols_c))\n",
    "print('The test error of lmm is {}, wls is {}, and ols is {}'.format(Error_te_lmm, Error_te_wls, Error_te_ols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with random generated test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "W_te_random = np.random.choice([0,1,2], [n_te, sc])\n",
    "X_te_random = np.concatenate([np.ones([n_te,1]), W_te_random[:, :num_large_effet_terms]], axis = 1)\n",
    "epsilon = np.random.normal(0, np.sqrt(sigma_e2), n_te)\n",
    "y_te_random = W_te_random@ beta[1:]  + beta[0] + epsilon\n",
    "y_te_random = scaler.transform(y_te_random.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV error of   lmm is 0.570717391987545, wls is 0.815208575193165, and ols is 0.7889778369665089\n",
      "The CVc error of  lmm is 0.75351097478136, wls is 0.8820716347147919, and ols is 0.9662938448730906\n",
      "The test error of lmm is 1.197072031836794, wls is 1.3104474383943825, and ols is 1.3572920774488901\n"
     ]
    }
   ],
   "source": [
    "# Using Test Error to estimate the Generalization error\n",
    "Error_cv_lmm = 1/n_tr * (np.sum(np.square(y_tr - H_cv_lmm2 @ y_tr)))\n",
    "Error_cv_wls = 1/n_tr * (np.sum(np.square(y_tr - H_cv_wls2 @ y_tr)))\n",
    "Error_cv_ols = 1/n_tr * (np.sum(np.square(y_tr - H_cv_ols2 @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "V_inv = fast.V_inv()\n",
    "# using estimated sigma_g2 to get the Covariance(y_tr, y_te)\n",
    "V_tr_te = 1/sc * fast.sigma_g2 * W_tr @ W_te_random.T\n",
    "\n",
    "H_te_wls = X_te_random @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv\n",
    "H_te_lmm = H_te_wls + V_tr_te.T @ V_inv @ (np.identity(n_tr) - X_tr @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv) \n",
    "H_te_ols = X_te_random @ u.inv(X_tr.T @ X_tr) @ X_tr.T\n",
    "\n",
    "V = fast.V()\n",
    "Correction_lmm = 2 * (1/n_tr * np.trace(H_cv_lmm2 @ V) - 1/n_te * np.trace(H_te_lmm @ V_tr_te))\n",
    "Correction_wls = 2 * (1/n_tr * np.trace(H_cv_wls2 @ V) - 1/n_te * np.trace(H_te_wls @ V_tr_te))\n",
    "Correction_ols = 2 * (1/n_tr * np.trace(H_cv_ols2 @ V) - 1/n_te * np.trace(H_te_ols @ V_tr_te))\n",
    "\n",
    "Error_cv_lmm_c = Error_cv_lmm + Correction_lmm\n",
    "Error_cv_wls_c = Error_cv_wls + Correction_wls\n",
    "Error_cv_ols_c = Error_cv_ols + Correction_ols\n",
    "\n",
    "Error_te_lmm = 1/n_te *(np.sum(np.square(y_te_random - H_te_lmm @ y_tr)))\n",
    "Error_te_wls = 1/n_te *(np.sum(np.square(y_te_random - H_te_wls @ y_tr)))\n",
    "Error_te_ols = 1/n_te *(np.sum(np.square(y_te_random - H_te_ols @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "print('The CV error of   lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm, Error_cv_wls, Error_cv_ols))\n",
    "print('The CVc error of  lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm_c, Error_cv_wls_c, Error_cv_ols_c))\n",
    "print('The test error of lmm is {}, wls is {}, and ols is {}'.format(Error_te_lmm, Error_te_wls, Error_te_ols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "434.8573883516204"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te_random_hat = X_te_random @ u.inv(X_te_random.T @ X_te_random) @ X_te_random.T @ y_te_random\n",
    "print(y_te_random_hat.shape)\n",
    "np.sum(np.square(y_te_random_hat - y_te_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV with k folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 fold indices : [(0, 204), (204, 408), (408, 612), (612, 816), (816, 1020)]\n",
      "--- start function H_function_ols ---\n",
      "Singluar Matrix\n",
      "------ 0.0880 seconds -----\n",
      "--- start function H_function_ols ---\n",
      "Singluar Matrix\n",
      "------ 0.1370 seconds -----\n",
      "--- start function H_function_ols ---\n",
      "Singluar Matrix\n",
      "------ 0.1280 seconds -----\n",
      "--- start function H_function_ols ---\n",
      "Singluar Matrix\n",
      "------ 0.0850 seconds -----\n",
      "--- start function H_function_ols ---\n",
      "Singluar Matrix\n",
      "------ 0.0910 seconds -----\n",
      "--- start function H_function_ols ---\n",
      "Singluar Matrix\n",
      "------ 0.0770 seconds -----\n",
      "--- start function H_function_ols ---\n",
      "Singluar Matrix\n",
      "------ 0.1410 seconds -----\n",
      "--- start function H_function_ols ---\n",
      "Singluar Matrix\n",
      "------ 0.0870 seconds -----\n",
      "--- start function H_function_ols ---\n",
      "Singluar Matrix\n",
      "------ 0.0460 seconds -----\n",
      "--- start function H_function_ols ---\n",
      "Singluar Matrix\n",
      "------ 0.0430 seconds -----\n"
     ]
    }
   ],
   "source": [
    "@timing\n",
    "def H_function_ols(X_minus_k, X_k, y_minus_k, y_k ):\n",
    "    return X_k @ u.inv(X_minus_k.T @ X_minus_k) @ X_minus_k.T\n",
    "\n",
    "H_cv_ols_k = getHcv_for_Kfolds(X_tr, y_tr, H_function_ols, nfolds = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 fold indices : [(0, 204), (204, 408), (408, 612), (612, 816), (816, 1020)]\n",
      "--- start function H_function_wls ---\n",
      "Singluar Matrix\n",
      "------ 0.2223 seconds -----\n",
      "--- start function H_function_wls ---\n",
      "Singluar Matrix\n",
      "------ 0.2080 seconds -----\n",
      "--- start function H_function_wls ---\n",
      "Singluar Matrix\n",
      "------ 0.2540 seconds -----\n",
      "--- start function H_function_wls ---\n",
      "Singluar Matrix\n",
      "------ 0.2530 seconds -----\n",
      "--- start function H_function_wls ---\n",
      "Singluar Matrix\n",
      "------ 0.2721 seconds -----\n",
      "--- start function H_function_wls ---\n",
      "Singluar Matrix\n",
      "------ 0.2800 seconds -----\n",
      "--- start function H_function_wls ---\n",
      "Singluar Matrix\n",
      "------ 0.2670 seconds -----\n",
      "--- start function H_function_wls ---\n",
      "Singluar Matrix\n",
      "------ 0.2930 seconds -----\n",
      "--- start function H_function_wls ---\n",
      "Singluar Matrix\n",
      "------ 0.3130 seconds -----\n",
      "--- start function H_function_wls ---\n",
      "Singluar Matrix\n",
      "------ 0.2340 seconds -----\n"
     ]
    }
   ],
   "source": [
    "@timing\n",
    "def H_function_wls(X_minus_k, X_k, y_minus_k, y_k, V):\n",
    "    V_inv = u.inv(V)\n",
    "    inverse = u.inv(X_minus_k.T @ V_inv @ X_minus_k) \n",
    "    return X_k @ inverse @ X_minus_k.T @ V_inv\n",
    "\n",
    "H_cv_wls_k = getHcv_for_Kfolds(X_tr, y_tr, H_function_wls, fast.V(), nfolds = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singluar Matrix\n",
      "First 5 fold indices : [(0, 204), (204, 408), (408, 612), (612, 816), (816, 1020)]\n"
     ]
    }
   ],
   "source": [
    "H_cv_lmm_k = np.zeros([n_tr, n_tr])\n",
    "V_inv = fast.V_inv()\n",
    "inverse = u.inv (X_tr.T @ V_inv @ X_tr)\n",
    "H_cv_temp = X_tr @ inverse @ X_tr.T @ V_inv\n",
    "\n",
    "folds_indices = get_folds_indices(10, n_tr)\n",
    "# get H_temp\n",
    "for Kindices in folds_indices:\n",
    "    ia,ib = Kindices\n",
    "    indices_minus_K = list(range(0, ia)) + list(range(ib, n_tr))\n",
    "\n",
    "    V_minus_k = V[indices_minus_K,:][:, indices_minus_K]\n",
    "    X_k = X_tr[ia:ib,:]\n",
    "    X_minus_k = X_tr[indices_minus_K,]\n",
    "\n",
    "    V_inv = u.inv(V_minus_k)\n",
    "\n",
    "    H_cv_temp = X_minus_k @ inverse @ X_minus_k.T @ V_inv\n",
    "\n",
    "    # inverse = u.inv(X_minus_k.T @ V_inv @ X_minus_k) \n",
    "\n",
    "    # temp =  X_k @ inverse @ X_minus_k.T @ V_inv\n",
    "    # H_cv_temp.append(temp)\n",
    "    \n",
    "    temp_u= V[ia:ib, indices_minus_K] @ u.inv(V_minus_k) @(\n",
    "        np.identity(n_tr - (ib - ia)) - H_cv_temp #[indices_minus_K,:][:, indices_minus_K]\n",
    "    )\n",
    "\n",
    "    H_cv_lmm_k[ia:ib, indices_minus_K] = H_cv_wls_k[ia:ib, indices_minus_K] + temp_u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "Singluar Matrix\n",
      "The CV error of   lmm is 3087.6077552037914, wls is 5161.92982704929, and ols is 4136.121047804878\n",
      "The CVc error of  lmm is 3232.9479590357723, wls is 5247.557933760587, and ols is 4170.160725917108\n",
      "The test error of lmm is 3300.216519590428, wls is 5855.715343084947, and ols is 4635.659955401074\n"
     ]
    }
   ],
   "source": [
    "# Using Test Error to estimate the Generalization error\n",
    "Error_cv_lmm = 1/n_tr * (np.sum(np.square(y_tr - H_cv_lmm_k @ y_tr)))\n",
    "Error_cv_wls = 1/n_tr * (np.sum(np.square(y_tr - H_cv_wls_k @ y_tr)))\n",
    "Error_cv_ols = 1/n_tr * (np.sum(np.square(y_tr - H_cv_ols_k @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "V_inv = fast.V_inv()\n",
    "# using estimated sigma_g2 to get the Covariance(y_tr, y_te)\n",
    "V_tr_te = 1/sc * fast.sigma_g2 * W_tr @ W_te.T\n",
    "\n",
    "H_te_wls = X_te @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv\n",
    "H_te_lmm = H_te_wls + V_tr_te.T @ V_inv @ (np.identity(n_tr) - X_tr @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv) \n",
    "H_te_ols = X_te @ u.inv(X_tr.T @ X_tr) @ X_tr.T\n",
    "\n",
    "V = fast.V()\n",
    "Correction_lmm = 2 * (1/n_tr * np.trace(H_cv_lmm_k @ V) - 1/n_te * np.trace(H_te_lmm @ V_tr_te))\n",
    "Correction_wls = 2 * (1/n_tr * np.trace(H_cv_wls_k @ V) - 1/n_te * np.trace(H_te_wls @ V_tr_te))\n",
    "Correction_ols = 2 * (1/n_tr * np.trace(H_cv_ols_k @ V) - 1/n_te * np.trace(H_te_ols @ V_tr_te))\n",
    "\n",
    "Error_cv_lmm_c = Error_cv_lmm + Correction_lmm\n",
    "Error_cv_wls_c = Error_cv_wls + Correction_wls\n",
    "Error_cv_ols_c = Error_cv_ols + Correction_ols\n",
    "\n",
    "Error_te_lmm = 1/n_te *(np.sum(np.square(y_te - H_te_lmm @ y_tr)))\n",
    "Error_te_wls = 1/n_te *(np.sum(np.square(y_te - H_te_wls @ y_tr)))\n",
    "Error_te_ols = 1/n_te *(np.sum(np.square(y_te - H_te_ols @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "print('The CV error of   lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm, Error_cv_wls, Error_cv_ols))\n",
    "print('The CVc error of  lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm_c, Error_cv_wls_c, Error_cv_ols_c))\n",
    "print('The test error of lmm is {}, wls is {}, and ols is {}'.format(Error_te_lmm, Error_te_wls, Error_te_ols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge\n",
    "\n",
    "\n",
    "$$\n",
    "Q(\\boldsymbol{\\beta})=\\frac{1}{n}(\\mathbf{y}-\\mathbf{X} \\boldsymbol{\\beta})^{\\prime}(\\mathbf{y}-\\mathbf{X} \\boldsymbol{\\beta})+ \\lambda ||{\\beta}||_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat \\beta = \\left(X^\\top X +n \\lambda \\mathbf{I} \\right)^{-1} X^{\\top} Y\n",
    "$$\n",
    "\n",
    "So the \n",
    "$$\n",
    "\\hat Y = H Y = X \\left(X^\\top X + n\\lambda \\mathbf{I} \\right)^{-1} X^{\\top} Y\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and testing error of Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error of ridge is 3812.3857, corrected training error is 3957.7259, test error is 4355.1305\n"
     ]
    }
   ],
   "source": [
    "n_tr,p = X_tr.shape\n",
    "\n",
    "nlamb = 10\n",
    "beta_without_y = u.inv(X_tr.T @ X_tr + nlamb * np.identity(p)) @ X_tr.T\n",
    "beta_hat_ridge = beta_without_y @ y_tr\n",
    "H_tr_ridge = X_tr @ beta_without_y\n",
    "H_te_ridge = X_te @ beta_without_y\n",
    "y_tr_hat_ridge = H_tr_ridge @ y_tr\n",
    "y_te_hat_ridge = H_te_ridge @ y_tr \n",
    "\n",
    "tr_error_ridge = 1/n_tr * np.sum((y_tr-y_tr_hat_ridge) ** 2)\n",
    "te_error_ridge = 1/n_te * np.sum((y_te-y_te_hat_ridge) ** 2)\n",
    "\n",
    "Correction_ridge = 2 * (1/n_tr * np.trace(H_tr_ridge @ V) - 1/n_te * np.trace(H_te_ridge @ V_tr_te))\n",
    "tr_error_ridge_c = tr_error_ridge + Correction_lmm\n",
    "print('training error of ridge is {:.4f}, corrected training error is {:.4f}, test error is {:.4f}'.\n",
    "    format(tr_error_ridge, tr_error_ridge_c, te_error_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOO Cross-valication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tr,p = X_tr.shape\n",
    "H_cv_ridge = np.zeros([n_tr,n_tr])\n",
    "\n",
    "lamb = 100 \n",
    "for i in range(n_tr):\n",
    "    indices_mi= list(range(n_tr))\n",
    "    indices_mi.remove(i)\n",
    "    X_minusi = X_tr[indices_mi, :]\n",
    "    inverse = u.inv(X_minusi.T @  X_minusi + lamb * np.diag(np.ones(p)) )\n",
    "\n",
    "    temp = X_tr[i,:] @ inverse @ X_minusi.T  \n",
    "    H_cv_ridge[i, indices_mi] = temp\n",
    "\n",
    "np.savez('Parameters/H_cv ridge.npz', H_cv_ridge = H_cv_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error of ridge is 0.8204, corrected training error is 0.9965, test error is 0.8893\n"
     ]
    }
   ],
   "source": [
    "Error_cv_ridge = 1/n_tr * (np.sum((y_tr - H_cv_ridge @ y_tr)**2))\n",
    "\n",
    "H_te_ridge = X_te @ u.inv(X_tr.T @ X_tr + lamb * np.identity(p)) @ X_tr.T\n",
    "Error_te_ridge = 1/n_te * (np.sum((y_te - H_te_ridge @ y_tr)**2))\n",
    "\n",
    "\n",
    "Correction_ridge = 2  * (np.trace(H_cv_ridge @ V)/n_tr - np.trace(H_te_ridge @ V_tr_te) /n_te)\n",
    "Error_cv_ridge_c = Error_cv_ridge + Correction_ridge\n",
    "\n",
    "print('training error of ridge is {:.4f}, corrected training error is {:.4f}, test error is {:.4f}'.\n",
    "    format(Error_cv_ridge, Error_cv_ridge_c, Error_te_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CV with k folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 fold indices : [(0, 204), (204, 408), (408, 612), (612, 816), (816, 1020)]\n",
      "--- start function H_function_ridge ---\n",
      "------ 0.1010 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 0.0740 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 0.0360 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 0.0430 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 0.0480 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 0.0750 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 0.0370 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 0.0430 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 0.0530 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 0.0410 seconds -----\n"
     ]
    }
   ],
   "source": [
    "lamb = 100\n",
    "@timing\n",
    "def H_function_ridge(X_minus_k, X_k, y_minus_k, y_k ):\n",
    "\n",
    "    return X_k @ u.inv(X_minus_k.T @ X_minus_k + lamb * np.identity(X_minus_k.shape[1])) @ X_minus_k.T\n",
    "\n",
    "H_cv_ridge_k = getHcv_for_Kfolds(X_tr, y_tr, H_function_ridge, nfolds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV error and CVc error and test error of ridge are 3975.5131, 4014.2003, 4322.9978\n"
     ]
    }
   ],
   "source": [
    "V = fast.V()\n",
    "V_tr_te = 1/sc * fast.sigma_g2* W_tr @ W_te.T\n",
    "Error_cv_ridge = 1/n_tr * (np.sum((y_tr - H_cv_ridge_k @ y_tr)**2))\n",
    "\n",
    "p = X_tr.shape[1]\n",
    "H_te_ridge = X_te @ u.inv(X_tr.T @ X_tr + lamb * np.identity(p)) @ X_tr.T\n",
    "Error_te_ridge = 1/n_te * (np.sum((y_te - H_te_ridge @ y_tr)**2))\n",
    "\n",
    "\n",
    "Correction_ridge = 2  * (1/n_tr*np.trace(H_cv_ridge_k @ V) - 1/n_te * np.trace(H_te_ridge @ V_tr_te))\n",
    "Error_cv_ridge_c = Error_cv_ridge + Correction_ridge\n",
    "\n",
    "print('The CV error and CVc error and test error of ridge are {:.4f}, {:.4f}, {:.4f}'\n",
    ".format(Error_cv_ridge, Error_cv_ridge_c, Error_te_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge using all SNPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to using all SNPs as the covariates for the ridge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_all = np.concatenate([X_tr[:,[0]], W_tr[:,:]], axis=1)\n",
    "X_te_all = np.concatenate([X_te[:,[0]], W_te[:,:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_tr_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\OneDrive\\Programming\\Python\\CVc_in_bio_informatics\\simulation.ipynb Cell 93\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y161sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m n_tr,p \u001b[39m=\u001b[39m X_tr_all\u001b[39m.\u001b[39mshape\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y161sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m nlamb \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/CVc_in_bio_informatics/simulation.ipynb#Y161sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m beta_without_y \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39minv(X_tr_all\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m X_tr_all \u001b[39m+\u001b[39m nlamb \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39midentity(p)) \u001b[39m@\u001b[39m X_tr_all\u001b[39m.\u001b[39mT\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_tr_all' is not defined"
     ]
    }
   ],
   "source": [
    "n_tr,p = X_tr_all.shape\n",
    "\n",
    "nlamb = 0\n",
    "beta_without_y = u.inv(X_tr_all.T @ X_tr_all + nlamb * np.identity(p)) @ X_tr_all.T\n",
    "beta_hat_ridge = beta_without_y @ y_tr\n",
    "H_tr_ridge = X_tr_all @ beta_without_y\n",
    "H_te_ridge = X_te_all @ beta_without_y\n",
    "y_tr_hat_ridge = H_tr_ridge @ y_tr\n",
    "y_te_hat_ridge = H_te_ridge @ y_tr \n",
    "\n",
    "tr_error_ridge = 1/n_tr * np.sum((y_tr-y_tr_hat_ridge) ** 2)\n",
    "te_error_ridge = 1/n_te * np.sum((y_te-y_te_hat_ridge) ** 2)\n",
    "\n",
    "Correction_ridge = 2 * (1/n_tr * np.trace(H_tr_ridge @ V) - 1/n_te * np.trace(H_te_ridge @ V_tr_te))\n",
    "tr_error_ridge_c = tr_error_ridge + Correction_lmm\n",
    "print('training error of ridge is {:.4f}, corrected training error is {:.4f}, test error is {:.4f}'.\n",
    "    format(tr_error_ridge, tr_error_ridge_c, te_error_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error of ridge is 0.2840, corrected training error is 0.3159, test error is 0.7724\n"
     ]
    }
   ],
   "source": [
    "n_tr,p = X_tr_all.shape\n",
    "\n",
    "nlamb = 10 \n",
    "beta_without_y = u.inv(X_tr_all.T @ X_tr_all + nlamb * np.identity(p)) @ X_tr_all.T\n",
    "beta_hat_ridge = beta_without_y @ y_tr\n",
    "H_tr_ridge = X_tr_all @ beta_without_y\n",
    "H_te_ridge = X_te_all @ beta_without_y\n",
    "y_tr_hat_ridge = H_tr_ridge @ y_tr\n",
    "y_te_hat_ridge = H_te_ridge @ y_tr \n",
    "\n",
    "tr_error_ridge = 1/n_tr * np.sum((y_tr-y_tr_hat_ridge) ** 2)\n",
    "te_error_ridge = 1/n_te * np.sum((y_te-y_te_hat_ridge) ** 2)\n",
    "\n",
    "Correction_ridge = 2 * (1/n_tr * np.trace(H_tr_ridge @ V) - 1/n_te * np.trace(H_te_ridge @ V_tr_te))\n",
    "tr_error_ridge_c = tr_error_ridge + Correction_lmm\n",
    "print('training error of ridge is {:.4f}, corrected training error is {:.4f}, test error is {:.4f}'.\n",
    "    format(tr_error_ridge, tr_error_ridge_c, te_error_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model with random generated data `X_te_random` and `y_te_random`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error of ridge is 0.2840, corrected training error is 0.3942, test error is 6.3486\n"
     ]
    }
   ],
   "source": [
    "V_inv = fast.V_inv()\n",
    "# using estimated sigma_g2 to get the Covariance(y_tr, y_te)\n",
    "V_tr_te = 1/sc * fast.sigma_g2 * W_tr @ W_te_random.T\n",
    "\n",
    "# using all 2000 snps with the intercept terms\n",
    "X_te_random_all = np.concatenate([X_te_random[:,[0]], W_te_random[:,:]], axis = 1)\n",
    "H_te_ridge = X_te_random_all @ beta_without_y \n",
    "y_te_random_hat_ridge = H_te_ridge @ y_tr\n",
    "\n",
    "\n",
    "V = fast.V()\n",
    "Correction_ridge = 2 * (1/n_tr * np.trace(H_tr_ridge @ V) - 1/ n_te * np.trace(H_te_ridge @ V_tr_te))\n",
    "tr_error_ridge_c = tr_error_ridge + Correction_ridge\n",
    "\n",
    "te_error_ridge_all = 1/n_te * np.sum((y_te_random - y_te_random_hat_ridge) ** 2)\n",
    "\n",
    "print('training error of ridge is {:.4f}, corrected training error is {:.4f}, test error is {:.4f}'.\n",
    "    format(tr_error_ridge, tr_error_ridge_c, te_error_ridge_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using K-folds cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 fold indices : [(0, 204), (204, 408), (408, 612), (612, 816), (816, 1020)]\n",
      "--- start function H_function_ridge ---\n",
      "------ 63.8100 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 65.8899 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 65.6386 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 69.7300 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 64.6101 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 64.4843 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 64.6963 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 66.8952 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 66.2335 seconds -----\n",
      "--- start function H_function_ridge ---\n",
      "------ 90.0654 seconds -----\n"
     ]
    }
   ],
   "source": [
    "lamb = 100\n",
    "@timing\n",
    "def H_function_ridge(X_minus_k, X_k, y_minus_k, y_k ):\n",
    "    return X_k @ u.inv(X_minus_k.T @ X_minus_k + lamb * np.identity(X_minus_k.shape[1])) @ X_minus_k.T\n",
    "\n",
    "H_cv_ridge_all_k = getHcv_for_Kfolds(X_tr_all, y_tr, H_function_ridge, nfolds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV error and CVc error and test error of ridge are 0.6286, 0.6267, 0.7724\n"
     ]
    }
   ],
   "source": [
    "V = fast.V()\n",
    "V_tr_te = 1/sc * fast.sigma_g2* W_tr @ W_te.T\n",
    "Error_cv_ridge = 1/n_tr * (np.sum((y_tr - H_cv_ridge_all_k @ y_tr)**2))\n",
    "\n",
    "p = X_tr_all.shape[1]\n",
    "# H_te_ridge = X_te_all @ u.inv(X_tr_all.T @ X_tr_all + lamb * np.identity(p)) @ X_tr_all.T\n",
    "H_te_ridge = X_te_all @ beta_without_y\n",
    "Error_te_ridge = 1/n_te * (np.sum((y_te - H_te_ridge @ y_tr)**2))\n",
    "\n",
    "\n",
    "Correction_ridge = 2  * (1/n_tr*np.trace(H_cv_ridge_all_k @ V) - 1/n_te * np.trace(H_te_ridge @ V_tr_te))\n",
    "Error_cv_ridge_c = Error_cv_ridge + Correction_ridge\n",
    "\n",
    "print('The CV error and CVc error and test error of ridge are {:.4f}, {:.4f}, {:.4f}'\n",
    ".format(Error_cv_ridge, Error_cv_ridge_c, Error_te_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16750499612001546\n",
      "The CV error and CVc error and test error of ridge are 0.82, 0.99, 0.64\n"
     ]
    }
   ],
   "source": [
    "# using theoretical sigma\n",
    "# V = fast.V(sigma_g2=sigma_g2_test, sigma_e2 = sigma_e2)\n",
    "# V =  1/sc * sigma_g2_test * W_tr @ W_tr.T + sigma_e2 * np.identity(X_tr.shape[0])\n",
    "V = fast.V()\n",
    "V_tr_te = 1/sc * fast.sigma_g2* W_tr@ W_te_random.T\n",
    "Error_cv_ridge = 1/n_tr * (np.sum((y_tr - H_cv_ridge_k @ y_tr)**2))\n",
    "\n",
    "H_te_ridge = X_te_all @ u.inv(X_tr_all.T @ X_tr_all + lamb * np.identity(p)) @ X_tr_all.T\n",
    "Error_te_ridge = 1/n_te * (np.sum((y_te - H_te_ridge @ y_tr)**2))\n",
    "\n",
    "\n",
    "Correction_ridge = 2  * (1/n_tr*np.trace(H_cv_ridge_k @ V) - 1/n_te * np.trace(H_te_ridge @ V_tr_te))\n",
    "Error_cv_ridge_c = Error_cv_ridge + Correction_ridge\n",
    "\n",
    "print(Correction_ridge)\n",
    "print('The CV error and CVc error and test error of ridge are {:.2f}, {:.2f}, {:.2f}'\n",
    ".format(Error_cv_ridge, Error_cv_ridge_c, Error_te_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOO Cross-valication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tr,p = X_tr_all.shape\n",
    "H_cv_ridge = np.zeros([n_tr,n_tr])\n",
    "\n",
    "lamb = 100 \n",
    "for i in range(n_tr):\n",
    "    indices_mi= list(range(n_tr))\n",
    "    indices_mi.remove(i)\n",
    "    X_minusi = X_tr_all[indices_mi, :]\n",
    "    inverse = u.inv(X_minusi.T @  X_minusi + lamb * np.diag(np.ones(p)) )\n",
    "\n",
    "    temp = X_tr_all[i,:] @ inverse @ X_minusi.T  \n",
    "    H_cv_ridge[i, indices_mi] = temp\n",
    "\n",
    "np.savez('Parameters/H_cv ridge.npz', H_cv_ridge = H_cv_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV error and CVc error and test error of ridge are 3971.16, 4005.64, 4310.60\n"
     ]
    }
   ],
   "source": [
    "Error_cv_ridge = 1/n_tr * (np.sum((y_tr - H_cv_ridge @ y_tr)**2))\n",
    "\n",
    "H_te_ridge = X_te @ u.inv(X_tr.T @ X_tr + lamb * np.identity(p)) @ X_tr.T\n",
    "Error_te_ridge = 1/n_te * (np.sum((y_te - H_te_ridge @ y_tr)**2))\n",
    "\n",
    "\n",
    "Correction_ridge = 2  * (np.trace(H_cv_ridge @ V)/n_tr - np.trace(H_te_ridge @ V_tr_te) /n_te)\n",
    "Error_cv_ridge_c = Error_cv_ridge + Correction_ridge\n",
    "\n",
    "print('The CV error and CVc error and test error of ridge are {:.2f}, {:.2f}, {:.2f}'\n",
    ".format(Error_cv_ridge, Error_cv_ridge_c, Error_te_ridge))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
